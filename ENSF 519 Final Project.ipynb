{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> ENSF 519.01 Applied Data Scince </center></h1>\n",
    "<h2><center> Final Project </center></h2>\n",
    "<h3><center> Oscar Predictions from Movie Scripts </center></h3>\n",
    "<p><center> Mark Ricalde, Paul Chen, Brian Pho, Harjee Johal <center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'script'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'script'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f0d676fce767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Cleaning the script\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"script\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"script\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Features/Labels for classifying whether a movie will win an oscar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'script'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def clean_text(text):\n",
    "    #Lower casing the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Removing punctuation\n",
    "    translation = text.maketrans(\"\", \"\", string.punctuation)\n",
    "    text = text.translate(translation)\n",
    "    re.sub(\"\\s\\s+\", \" \", text)\n",
    "    \n",
    "    #Removing stop words\n",
    "    text = \" \".join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "    \n",
    "    #Stemming the words\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('oscar_data.csv') # TODO - Replace dummy csv with real merged csv\n",
    "\n",
    "# Cleaning the script\n",
    "data[\"script\"] = data[\"script\"].apply(clean_text)\n",
    "\n",
    "# Features/Labels for classifying whether a movie will win an oscar\n",
    "features_1 = data.loc[:, data.columns != 'winner']\n",
    "labels_1   = data[\"winner\"]\n",
    "\n",
    "# Features/Labels for classifying what category a movie will be in\n",
    "features_2 = data.loc[:, data.columns != 'category']\n",
    "labels_2   = data[\"category\"]\n",
    "   \n",
    "# Splitting the data set\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features_1, labels_1, stratify=labels_1, test_size=0.2)\n",
    "\n",
    "# Vectorizing the training set\n",
    "# TODO - Only vectorize textual features\n",
    "# tfidf_vect = TfidfVectorizer().fit(xtrain)\n",
    "# xtrain     = tfidf_vect.transform(xtrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nDownloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n17465344/17464789 [==============================] - 1s 0us/step\n[1 0 0 ... 0 1 0]\n"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>script</th>\n      <th>won</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>When Worlds Collide</td>\n      <td>['needl', 'heaven', 'haystack', 'star', 'heave...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Reds</td>\n      <td>['rememb', 'im', 'begin', 'forget', 'peopl', '...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Undefeated</td>\n      <td>['let', 'start', 'right', 'guard', 'shot', 'lo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Seven Brides for Seven Brothers</td>\n      <td>['deliv', 'perfectionand', 'dont', 'brag', 'd'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Henry V</td>\n      <td>['oh', 'muse', 'ascend', 'brightest', 'heaven'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7441</th>\n      <td>The Roommate</td>\n      <td>['hi', 'hi', 'sara', 'matthew', 'sara', 'matth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7442</th>\n      <td>Night of the Comet</td>\n      <td>['record', 'time', 'swung', 'univers', 'ellipt...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7443</th>\n      <td>Paddington</td>\n      <td>['darkest', 'peru', 'vast', 'unexplor', 'wilde...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7444</th>\n      <td>Jumanji: Welcome to the Jungle</td>\n      <td>['ocean', 'wave', 'crash', 'seagul', 'squawk',...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7445</th>\n      <td>Pitch Perfect</td>\n      <td>['exact', 'type', 'perform', 'expect', 'intern...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3200 rows × 3 columns</p>\n</div>",
      "text/plain": "                                title  \\\n1                 When Worlds Collide   \n5                                Reds   \n12                         Undefeated   \n15    Seven Brides for Seven Brothers   \n25                            Henry V   \n...                               ...   \n7441                     The Roommate   \n7442               Night of the Comet   \n7443                       Paddington   \n7444   Jumanji: Welcome to the Jungle   \n7445                    Pitch Perfect   \n\n                                                 script  won  \n1     ['needl', 'heaven', 'haystack', 'star', 'heave...    1  \n5     ['rememb', 'im', 'begin', 'forget', 'peopl', '...    1  \n12    ['let', 'start', 'right', 'guard', 'shot', 'lo...    1  \n15    ['deliv', 'perfectionand', 'dont', 'brag', 'd'...    1  \n25    ['oh', 'muse', 'ascend', 'brightest', 'heaven'...    1  \n...                                                 ...  ...  \n7441  ['hi', 'hi', 'sara', 'matthew', 'sara', 'matth...    0  \n7442  ['record', 'time', 'swung', 'univers', 'ellipt...    0  \n7443  ['darkest', 'peru', 'vast', 'unexplor', 'wilde...    0  \n7444  ['ocean', 'wave', 'crash', 'seagul', 'squawk',...    0  \n7445  ['exact', 'type', 'perform', 'expect', 'intern...    0  \n\n[3200 rows x 3 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>script</th>\n      <th>won</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When Worlds Collide</td>\n      <td>['needl', 'heaven', 'haystack', 'star', 'heave...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Reds</td>\n      <td>['rememb', 'im', 'begin', 'forget', 'peopl', '...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Undefeated</td>\n      <td>['let', 'start', 'right', 'guard', 'shot', 'lo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Seven Brides for Seven Brothers</td>\n      <td>['deliv', 'perfectionand', 'dont', 'brag', 'd'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Henry V</td>\n      <td>['oh', 'muse', 'ascend', 'brightest', 'heaven'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3195</th>\n      <td>The Roommate</td>\n      <td>['hi', 'hi', 'sara', 'matthew', 'sara', 'matth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3196</th>\n      <td>Night of the Comet</td>\n      <td>['record', 'time', 'swung', 'univers', 'ellipt...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3197</th>\n      <td>Paddington</td>\n      <td>['darkest', 'peru', 'vast', 'unexplor', 'wilde...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3198</th>\n      <td>Jumanji: Welcome to the Jungle</td>\n      <td>['ocean', 'wave', 'crash', 'seagul', 'squawk',...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3199</th>\n      <td>Pitch Perfect</td>\n      <td>['exact', 'type', 'perform', 'expect', 'intern...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3200 rows × 3 columns</p>\n</div>",
      "text/plain": "                                title  \\\n0                 When Worlds Collide   \n1                                Reds   \n2                          Undefeated   \n3     Seven Brides for Seven Brothers   \n4                             Henry V   \n...                               ...   \n3195                     The Roommate   \n3196               Night of the Comet   \n3197                       Paddington   \n3198   Jumanji: Welcome to the Jungle   \n3199                    Pitch Perfect   \n\n                                                 script  won  \n0     ['needl', 'heaven', 'haystack', 'star', 'heave...    1  \n1     ['rememb', 'im', 'begin', 'forget', 'peopl', '...    1  \n2     ['let', 'start', 'right', 'guard', 'shot', 'lo...    1  \n3     ['deliv', 'perfectionand', 'dont', 'brag', 'd'...    1  \n4     ['oh', 'muse', 'ascend', 'brightest', 'heaven'...    1  \n...                                                 ...  ...  \n3195  ['hi', 'hi', 'sara', 'matthew', 'sara', 'matth...    0  \n3196  ['record', 'time', 'swung', 'univers', 'ellipt...    0  \n3197  ['darkest', 'peru', 'vast', 'unexplor', 'wilde...    0  \n3198  ['ocean', 'wave', 'crash', 'seagul', 'squawk',...    0  \n3199  ['exact', 'type', 'perform', 'expect', 'intern...    0  \n\n[3200 rows x 3 columns]"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scripts data\n",
    "script_csv_path = \"./processed_data/script_data.csv\"\n",
    "script_data = pd.read_csv(script_csv_path)\n",
    "script_data = script_data.drop(columns=[\"release_year\"])\n",
    "# display(script_data)\n",
    "\n",
    "# Get Oscar labels\n",
    "oscar_labels_path = \"./processed_data/oscar_data.csv\"\n",
    "oscar_label = pd.read_csv(oscar_labels_path).rename(columns={\"entity\": \"title\", \"category\": \"nominated\", \"winner\": \"won\"})\n",
    "oscar_label = oscar_label.drop(columns=[\"year\"])\n",
    "oscar_label[\"nominated\"] = True\n",
    "# display(oscar_label)\n",
    "\n",
    "# Merge script and Oscar data\n",
    "script_oscar_df = pd.merge(script_data, oscar_label, how=\"outer\", on=\"title\")\n",
    "script_oscar_df = script_oscar_df.dropna(subset=['script'])\n",
    "script_oscar_df = script_oscar_df.fillna(False)\n",
    "# display(script_oscar_df)\n",
    "\n",
    "script_oscar_df['nominated'].astype('bool')\n",
    "script_oscar_df['won'].astype('bool')\n",
    "# print(script_oscar_df.dtypes)\n",
    "# display(script_oscar_df)\n",
    "\n",
    "script_oscar_df = script_oscar_df[script_oscar_df['nominated'] == script_oscar_df['won']].drop_duplicates()\n",
    "script_oscar_df = script_oscar_df.drop(columns=['nominated'])\n",
    "script_oscar_df['won'] = script_oscar_df['won'].astype(int)\n",
    "script_oscar_df = script_oscar_df.reset_index(drop=True)\n",
    "\n",
    "display(script_oscar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, None, 32)          320000    \n_________________________________________________________________\nsimple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      \n_________________________________________________________________\nsimple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      \n_________________________________________________________________\nsimple_rnn_6 (SimpleRNN)     (None, None, 32)          2080      \n=================================================================\nTotal params: 326,240\nTrainable params: 326,240\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "max_features = 10000  # Number of words to consider as features\n",
    "maxlen = 500\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn_history = model.fit(input_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_results(simple_rnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_14\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, None, 32)          320000    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 32)                8320      \n_________________________________________________________________\ndense_21 (Dense)             (None, 1)                 33        \n=================================================================\nTotal params: 328,353\nTrainable params: 328,353\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = model.fit(input_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(lstm_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}